{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "\n",
    "\n",
    "# How often to record tensorboard summaries.\n",
    "SUMMARY_INTERVAL = 40\n",
    "\n",
    "# How often to run a batch through the validation model.\n",
    "VAL_INTERVAL = 200\n",
    "\n",
    "# How often to save a model checkpoint\n",
    "SAVE_INTERVAL = 400\n",
    "\n",
    "# tf record data location:\n",
    "DATA_DIR = '/home/xca64/vml4/dataset/ucf101/ucf101_imgs'\n",
    "\n",
    "# local output directory\n",
    "OUT_DIR = '/cs/vml4/xca64/robot_data/result'\n",
    "\n",
    "# summary output dir\n",
    "SUM_DIR = '/cs/vml4/xca64/robot_data/summaries'\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('data_dir', DATA_DIR, 'directory containing data.')\n",
    "flags.DEFINE_string('dataset_name', 'ucf', 'dataset used')\n",
    "flags.DEFINE_string('output_dir', OUT_DIR, 'directory for model checkpoints.')\n",
    "flags.DEFINE_string('gif_dir', '/cs/vml4/xca64/robot_data/gif/' , 'directory gif result')\n",
    "flags.DEFINE_integer('gif_nums', 5 , 'number of gif files to save')\n",
    "flags.DEFINE_string('event_log_dir',SUM_DIR, 'directory for writing summary.')\n",
    "flags.DEFINE_integer('num_iterations', 100000, 'number of training iterations.')\n",
    "flags.DEFINE_string('pretrained_model', '' ,\n",
    "                    'filepath of a pretrained model to initialize from.')\n",
    "\n",
    "flags.DEFINE_integer('sequence_length', 10,\n",
    "                     'sequence length, including context frames.')\n",
    "flags.DEFINE_integer('context_frames', 2, '# of frames before predictions.')\n",
    "flags.DEFINE_integer('use_state', 1,\n",
    "                     'Whether or not to give the state+action to the model')\n",
    "\n",
    "flags.DEFINE_string('model', 'prednet',\n",
    "                    'model architecture to use - prediction, prednet')\n",
    "\n",
    "flags.DEFINE_integer('num_masks', 10,\n",
    "                     'number of masks, usually 1 for DNA, 10 for CDNA, STN.')\n",
    "flags.DEFINE_float('schedsamp_k', 900.0,\n",
    "                   'The k hyperparameter for scheduled sampling,'\n",
    "                   '-1 for no scheduled sampling.')\n",
    "flags.DEFINE_float('train_val_split', 0.95,\n",
    "                   'The percentage of files to use for the training set,'\n",
    "                   ' vs. the validation set.')\n",
    "\n",
    "flags.DEFINE_float('gpu_memory_fraction', 1.0,\n",
    "                   'gpu percentage')\n",
    "\n",
    "flags.DEFINE_integer('batch_size', 32, 'batch size for training')\n",
    "flags.DEFINE_float('learning_rate', 0.001,\n",
    "                   'the base learning rate of the generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xca64/vml4/github/video_prediction/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ucf101_img_input import get_image_paths_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_dir = '/home/xca64/vml4/github/video_prediction/data/ucfTrainTestlist'\n",
    "images, labels = get_image_paths_and_labels(list_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9537,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "split='1'\n",
    "data_dir = '/cs/vml4/xca64/dataset/ucf101/ucf101_imgs/'\n",
    "list_dir = '/home/xca64/vml4/github/video_prediction/data/ucfTrainTestlist'\n",
    "\n",
    "training=True\n",
    "fileseq = []\n",
    "labelsseq = []\n",
    "if training:\n",
    "    # Load tranning samples\n",
    "    train_test_list = os.path.join(os.path.expanduser(list_dir),'trainlist_with_length0' + split + '.txt')\n",
    "else:\n",
    "    train_test_list = os.path.join(os.path.expanduser(list_dir),'testlist_with_length0' + split + '.txt')\n",
    "\n",
    "with open(train_test_list,\"r\") as text_file:\n",
    "    lines = text_file.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        tmp = line.split(' ')\n",
    "\n",
    "        labelsseq.append(int(tmp[2])*[tmp[1]])\n",
    "\n",
    "#         file_folder = os.path.join(os.path.expanduser(data_dir), tmp[0])\n",
    "#         filenames = []\n",
    "#         for i in random.sample(int(range(tmp[2])),  NROF_SAMPLES):\n",
    "#             filenames.append(os.path.join(file_folder, 'frame'+str(i)+'.jpg'))\n",
    "#         fileseq.append(filenames)\n",
    "        if(i>5):\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9537,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.train.start_queue_runners(sess)\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "tf.train.start_queue_runners(coord=coord, sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.platform import flags\n",
    "from tensorflow.python.platform import gfile\n",
    "import random\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Original image dimensions\n",
    "ORIGINAL_WIDTH = 320\n",
    "ORIGINAL_HEIGHT = 240\n",
    "COLOR_CHAN = 3\n",
    "\n",
    "# Default image dimensions.\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "NROF_SAMPLES = 20\n",
    "NROF_RANGES = 90\n",
    "\n",
    "data_dir = '/cs/vml4/xca64/dataset/ucf101/ucf101_imgs/'\n",
    "list_dir = '/home/xca64/vml4/github/video_prediction/data/ucfTrainTestlist'\n",
    "\n",
    "\n",
    "def get_image_paths_and_labels(list_dir, split='1', training=True):\n",
    "    \n",
    "    fileseq = []\n",
    "    labelsseq = []\n",
    "    if training:\n",
    "        # Load tranning samples\n",
    "        train_test_list = os.path.join(os.path.expanduser(list_dir),'trainlist0' + split + '.txt')\n",
    "    else:\n",
    "        train_test_list = os.path.join(os.path.expanduser(list_dir),'testlist0' + split + '.txt')\n",
    "\n",
    "    with open(train_test_list,\"r\") as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "            tmp = line.split(' ')\n",
    "            labelsseq.append(NROF_SAMPLES*[tmp[1][:-2]])\n",
    "\n",
    "            file_folder = os.path.join(os.path.expanduser(data_dir), tmp[0])\n",
    "            filenames = []\n",
    "            for i in random.sample(range(NROF_RANGES),  NROF_SAMPLES):\n",
    "                filenames.append(os.path.join(file_folder, 'frame'+str(i)+'.jpg'))\n",
    "            fileseq.append(filenames)\n",
    "            \n",
    "    return fileseq, labelsseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileseq, labelsseq = get_image_paths_and_labels(list_dir, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_queue = tf.train.input_producer(np.asarray(np.transpose([fileseq, labelsseq], (1,2,0))), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "tf.train.start_queue_runners(coord=coord, sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = input_queue.dequeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_and_labels = []\n",
    "fileinfo = input_queue.dequeue()\n",
    "\n",
    "indx = random.randint(0,NROF_SAMPLES)\n",
    "filename = fileinfo[indx,0]\n",
    "label = fileinfo[indx,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_contents = tf.read_file(filename)\n",
    "image = tf.image.decode_jpeg(file_contents)\n",
    "\n",
    "crop_size = min(ORIGINAL_HEIGHT, ORIGINAL_WIDTH)\n",
    "image = tf.image.resize_image_with_crop_or_pad(image, crop_size, crop_size)\n",
    "image = tf.reshape(image, [1, crop_size, crop_size, 3])\n",
    "image = tf.image.resize_bilinear(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "image = tf.cast(image, tf.float32) / 255.0\n",
    "#pylint: disable=no-member\n",
    "image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "image.set_shape((IMG_HEIGHT, IMG_WIDTH, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img,name = sess.run([image,filename]) \n",
    "# name = sess.run(filename)\n",
    "print(name)\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enter an interactive TensorFlow Session.\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# Initialize 'x' using the run() method of its initializer op.\n",
    "x.initializer.run()\n",
    "\n",
    "# Add an op to subtract 'a' from 'x'.  Run it and print the result\n",
    "print(x.eval())\n",
    "# ==> [-2. -1.]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
